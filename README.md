# Algoritmo de Huffman Embarcado

Este reposit√≥rio cont√©m uma implementa√ß√£o do **algoritmo de Huffman** em linguagem **C**, adaptada para **sistemas embarcados**. A implementa√ß√£o foi projetada para operar com **arrays est√°ticos** e **sem recurs√£o**, tornando-a ideal para dispositivos com recursos limitados, como microcontroladores.

---

## üìã Descri√ß√£o do Projeto

O **algoritmo de Huffman** √© amplamente utilizado para compress√£o de dados, gerando c√≥digos de comprimento vari√°vel com base na frequ√™ncia de ocorr√™ncia dos s√≠mbolos. Esta implementa√ß√£o foi desenvolvida com foco em:

- **Efici√™ncia em sistemas embarcados:** sem uso de aloca√ß√£o din√¢mica de mem√≥ria.
- **Simples de implementar e compreender:** usa estruturas iterativas no lugar de recurs√£o.
- **Compatibilidade:** projetada para ser port√°til e f√°cil de adaptar para diferentes plataformas embarcadas.

---

## ‚öôÔ∏è Funcionalidades

- **Compress√£o de Dados:** Reduz o tamanho de dados de entrada ao gerar c√≥digos compactados.
- **Estrutura Est√°tica:** Utiliza arrays fixos para representar a √°rvore de Huffman.
- **Iterativo:** Implementa√ß√£o sem recurs√£o, adequada para dispositivos embarcados com pilha limitada.
- **Exemplo de Compress√£o:** Gera c√≥digos de Huffman para s√≠mbolos e frequ√™ncias pr√©-definidos no c√≥digo.

---

## üí™ Estrutura do Projeto

- `huffman.c`: Implementa√ß√£o do algoritmo de Huffman.
- `README.md`: Documenta√ß√£o do projeto.
- `LICENSE`: Informa√ß√µes sobre a licen√ßa do reposit√≥rio.

---

## üöÄ Como Usar

### Pr√©-requisitos
- Compilador C (ex.: GCC ou outro compat√≠vel).
- Ambiente Linux, Windows, ou uma ferramenta de desenvolvimento para sistemas embarcados.

### Passos

1. **Clone o reposit√≥rio:**
   ```bash
   git clone https://github.com/SEU_USUARIO/Embedded-Huffman-Encoding.git
   ```
2. **Entre no diret√≥rio do projeto:**
   ```bash
   cd Embedded-Huffman-Encoding
   ```
3. **Compile o programa:**
   ```bash
   gcc huffman.c -o huffman
   ```
4. **Execute o programa:**
   ```bash
   ./huffman
   ```

### Resultado
Ao executar, o programa exibir√° os **c√≥digos de Huffman** gerados para os s√≠mbolos e frequ√™ncias predefinidos.

---

## üìä Aplica√ß√µes

Esta implementa√ß√£o √© ideal para compress√£o de dados em:
- **Dispositivos IoT:** Reduz o tamanho de dados transmitidos por sensores.
- **Armazenamento Compactado:** Minimiza o espa√ßo ocupado por arquivos em sistemas com mem√≥ria limitada.
- **Redu√ß√£o de Tr√°fego de Rede:** Otimiza o uso de largura de banda em redes embarcadas.

---

## üìÇ Estrutura do C√≥digo

### **√Årvore de Huffman**
- Representada usando arrays est√°ticos:
  - Cada n√≥ da √°rvore √© armazenado como uma estrutura contendo peso, √≠ndices de filhos e pai.
- √Årvore criada iterativamente, combinando n√≥s com os menores pesos.

### **C√≥digos de Huffman**
- Gerados ao percorrer a √°rvore de maneira iterativa (sem recurs√£o).
- Cada c√≥digo √© armazenado como uma string para facilitar a compress√£o.

---

## üìä Complexidade

A an√°lise de **tempo de complexidade** do **algoritmo de Huffman sem recurs√£o e sem aloca√ß√£o din√¢mica de mem√≥ria** pode ser feita avaliando as etapas principais da sua execu√ß√£o. A aus√™ncia de recurs√£o e aloca√ß√£o din√¢mica n√£o altera significativamente a complexidade assint√≥tica do algoritmo; essas altera√ß√µes apenas afetam a efici√™ncia pr√°tica (desempenho e uso de mem√≥ria).

---

### **Etapas do Algoritmo**

O algoritmo de Huffman pode ser dividido em duas etapas principais:

1. **Constru√ß√£o da √Årvore de Huffman:**
   - O objetivo √© encontrar repetidamente os dois n√≥s de menor peso e combin√°-los at√© restar um √∫nico n√≥, a raiz da √°rvore.
   - Na vers√£o sem recurs√£o, essa constru√ß√£o √© feita iterativamente.

2. **Gera√ß√£o dos C√≥digos de Huffman:**
   - Cada folha da √°rvore gera um c√≥digo de Huffman ao ser percorrida do n√≥ folha at√© a raiz.

---

### **Complexidade da Constru√ß√£o da √Årvore**

#### Melhor Caso:
- No melhor caso, as frequ√™ncias dos s√≠mbolos s√£o ordenadas em ordem crescente. Isso permite que os dois menores valores sejam encontrados imediatamente, sem necessidade de varreduras completas do conjunto.
- Encontrar os dois menores n√≥s, \(n - 1\) vezes, √© feito com complexidade \(O(n)\) para cada busca.
- **Complexidade no Melhor Caso:**  
  \[
  O(n \cdot n) = O(n^2)
  \]

#### Pior Caso:
- No pior caso, as frequ√™ncias dos s√≠mbolos n√£o est√£o ordenadas, e cada busca pelos dois menores valores requer uma varredura completa do conjunto restante de n√≥s.
- Para \(n\) n√≥s iniciais, h√° \(2n - 1\) n√≥s na √°rvore final. As buscas \(n - 1\) vezes no pior caso custam \(O(n^2)\).
- **Complexidade no Pior Caso:**  
  \[
  O(n^2)
  \]

---

### **Complexidade da Gera√ß√£o dos C√≥digos**

#### Melhor e Pior Caso:
- A gera√ß√£o dos c√≥digos envolve percorrer cada folha at√© a raiz. Como a altura da √°rvore √© \(O(\log n)\) no caso balanceado e as folhas est√£o associadas a \(n\) s√≠mbolos:
  - Cada s√≠mbolo √© percorrido em \(O(\log n)\).
  - Para \(n\) s√≠mbolos, isso resulta em:
    \[
    O(n \cdot \log n)
    \]

---

### **Complexidade Total**

A constru√ß√£o da √°rvore domina o tempo de execu√ß√£o, pois tem complexidade maior que a gera√ß√£o dos c√≥digos no caso assint√≥tico.

| **Etapa**               | **Melhor Caso**       | **Pior Caso**        |
|-------------------------|-----------------------|-----------------------|
| **Constru√ß√£o da √Årvore**| \(O(n^2)\)            | \(O(n^2)\)            |
| **Gera√ß√£o dos C√≥digos** | \(O(n \cdot \log n)\) | \(O(n \cdot \log n)\) |
| **Total**               | \(O(n^2)\)            | \(O(n^2)\)            |

---

### **Justificativa**

1. **Constru√ß√£o da √Årvore (etapa dominante):**  
   - A cada passo, os dois menores n√≥s s√£o combinados, o que exige uma busca linear no conjunto de n√≥s restantes. Isso √© repetido \(n - 1\) vezes, resultando em \(O(n^2)\).

2. **Gera√ß√£o dos C√≥digos:**  
   - √â menos custoso do que a constru√ß√£o da √°rvore, pois cada s√≠mbolo percorre um caminho at√© a raiz com complexidade proporcional √† altura da √°rvore (\(O(\log n)\)). Para \(n\) s√≠mbolos, a soma total dos percursos √© \(O(n \cdot \log n)\).

---

### **Conclus√£o**
O tempo de complexidade do **algoritmo de Huffman sem recurs√£o e aloca√ß√£o din√¢mica** √© o mesmo da vers√£o tradicional:
- Melhor Caso: \(O(n^2)\)
- Pior Caso: \(O(n^2)\)

Isso ocorre porque o gargalo principal do algoritmo est√° na constru√ß√£o da √°rvore, onde os dois menores pesos precisam ser encontrados repetidamente.
